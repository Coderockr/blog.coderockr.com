---
title: "Um Ambiente Simples Usando Kubernetes e OpenShift Next Gen ‚Äî Parte 2"
description: "Este post √© parte de uma s√©rie sobre o b√°sico necess√°rio para usar o Kubernetes..."
author: "Lucas Abreu"
date: 2017-03-08
draft: false
categories: ["Desenvolvimento"]
tags: ["Desenvolvimento", "Kubernetes", "Ferramentas"]
---

Este post √© parte de uma s√©rie sobre o b√°sico necess√°rio para usar o Kubernetes, caso voc√™ n√£o tenha lido os post anteriores recomendo l√™-los e depois voltar aqui para n√£o ficar perdido.

* Parte 1 ‚Äî Conceitos B√°sicos: [clique aqui](https://blog.coderockr.com/um-ambiente-simples-usando-kubernetes-e-openshift-next-gen-parte-1-d012d6eb5344)

* Parte 3 ‚Äî Volumes Persistentes: [clique aqui](https://medium.com/@lucassabreu/um-ambiente-simples-usando-kubernetes-e-openshift-next-gen-parte-3-a36e01e920cb)

* Parte 4 ‚Äî Segredos: [clique aqui](https://medium.com/@lucassabreu/um-ambiente-simples-usando-kubernetes-e-openshift-next-gen-parte-4-665505dbba59#.akd139siq)

Conhecendo os componentes b√°sicos explicados no [post anterior](https://blog.coderockr.com/um-ambiente-simples-usando-kubernetes-e-openshift-next-gen-parte-1-d012d6eb5344) posso preparar a aplica√ß√£o que mostrei para o Kubernetes.

O primeiro passo √© definir quais s√£o os Pods do meu cluster.

Embora o primeiro impulso seja colocar cada um dos cont√™ineres em um Pod distinto e seguir em frente, esse n√£o √© necessariamente a melhor forma de defini-los. Por exemplo, em situa√ß√£o certos cont√™ineres tem o mesmo objetivo, ou dependem muito um do outro √© uma boa ideia mant√™-los juntos.

Mas para a minha aplica√ß√£o faz mais sentido um Pod por cont√™iner, um para o servidor HTTP e outro para o banco de dados.

Como n√£o √© uma boa ideia simplesmente definir um Pod diretamente, criei dois Deployments o node-deployment e o db-deployment.

*No momento da escrita desse post os Deployments ainda estavam marcados como uma vers√£o beta, mas j√° s√£o bastante usados, ent√£o √© confi√°vel.*

<iframe src="https://medium.com/media/69c84fb1984593949d88a5f2fd61eb60" frameborder=0></iframe>

O primeiro Deployment √© para o db-deployment. Os arquivos de configura√ß√£o s√£o simples de ler, sempre come√ßamos o arquivo dizendo o tipo de objeto que ser√° criado, o metadata e definimos as specs (que variam para cada tipo de componente).

Defini que preciso de apenas um Pod (replica) e que as mesmas ser√£o identific√°veis pelas labels: name=db-pod.

Outras duas informa√ß√µes importantes s√£o ports e volumeMounts.

* ports define quais portas dever√£o ser expostas no Pod e permite que possam ser mapeadas nos Services posteriormente. Tamb√©m √© recomendado dar nomes √†s mesmas (mysql-port), assim podemos usar o nome como identificador no lugar de n√∫meros.

* volumeMounts define todos os volumes do cont√™iner, dessa forma o volume de dados do MySQL precisou ser mapeado (/var/lib/mysql).

<iframe src="https://medium.com/media/6d679886ea7b87dc1ed218faebb1dccf" frameborder=0></iframe>

O segundo Deployment √© do servidor HTTP, chamei-o de node-deployment. Ele segue as mesmas regras do anterior, sendo at√© mais simples.

A novidade aqui √© o db-service, que vou explicar agora:

<iframe src="https://medium.com/media/7f99fa74569679b605cf8f8af570ab14" frameborder=0></iframe>

O db-service √© o nome do Service que defini para agrupar os Pods de banco de dados, o Service ficou bem simples e basicamente tem duas partes:

* selector define uma regra para selecionar quais Pods fazem parte do Service, no caso estou usando uma regra bem simples de name=db-pod.

* ports permite que voc√™ mapeie as portas dos Pods para uma porta no Service, no caso estou roteando a porta de nome mysql-port para a 3306 do Service. Assim toda chamada para db-service:3306 ser√° direcionada para a mysql-port de um dos Pods.

<iframe src="https://medium.com/media/6ad94466f31893ff61116857683ba8f0" frameborder=0></iframe>

O node-service segue a mesma l√≥gica, mas para os Pods do servidor HTTP.

<iframe src="https://medium.com/media/0d9727d5f952a1334027422606daafea" frameborder=0></iframe>

Por fim criei uma Route para expor o servi√ßo node-service para a Internet. Eu poderia definir qual o nome de host, mas como n√£o o fiz o OpenShift ir√° gerar uma URL automaticamente para mim.

Essa URL pode ser descoberta entrando na Dashboard do OpenShift ou com o comando oc get routes:

<iframe src="https://medium.com/media/72962b149323439800ece6deb133716f" frameborder=0></iframe>

Para aplicar as configura√ß√µes no cluster a OpenShift disponibiliza um cliente de linha de comando, que usa basicamente a mesma estrutura do kubectl, o oc. Ent√£o tudo que precisa ser feito √© executar:

<iframe src="https://medium.com/media/5c231de454163f7a6a590edfb652e9f5" frameborder=0></iframe>

As instru√ß√µes de como instalar o cliente e configur√°-lo est√£o nesse link: [https://console.preview.openshift.com/console/command-line](https://console.preview.openshift.com/console/command-line).

### *** Update 2017‚Äì04‚Äì29 ***

Se estiver lendo esse artigo algum tempo depois de lan√ßado, a OpenShift fechou o preview e o link anterior n√£o funciona, mas ainda √© poss√≠vel baixar o oc client em:
[**openshift/origin**
*origin - Enterprise Kubernetes for Developers*github.com](https://github.com/openshift/origin/releases)

Caso n√£o queira criar os todos esses fontes, pode peg√°-los aqui: [https://github.com/lucassabreu/openshift-next-gen/tree/v1](https://github.com/lucassabreu/openshift-next-gen/tree/v1); ou executar:

    git clone -b v1 \
        [https://github.com/lucassabreu/openshift-next-gen.git](https://github.com/lucassabreu/openshift-next-gen.git)

Agora no console do OpenShift dever√£o aparecer todos esses componentes rodando.

![eu fiz algumas brincadeiras antes de chegar aqui, ent√£o tenho mais vers√µes dos deploys ‚ò∫](https://cdn-images-1.medium.com/max/2022/1*YAuHwlP-hLMdmI-f60mjAQ.png)*eu fiz algumas brincadeiras antes de chegar aqui, ent√£o tenho mais vers√µes dos deploys ‚ò∫*

Caso esteja acompanhando as etapas, voc√™ j√° deve ter visto esse Dashboard, mas caso esteja apenas lendo: esse Dashboard √© a tela principal dos clusters que voc√™ criar no OpenShift; basta clicar aqui, autenticar-se com o GitHub, criar um *Project*, e pronto em *Overview* voc√™ ver√° os componentes surgirem e sumirem em tempo real conforme vai aplicando as configura√ß√µes.

Voltando, nesse momento temos o mesmo comportamento da aplica√ß√£o local, rodando dentro do Kubernetes, empenhando o m√≠nimo poss√≠vel de configura√ß√£o.

Mas existem alguns problemas no que foi definido.

O primeiro √© que os db-pods est√£o totalmente ef√™meros, ou seja, se eu adicionar novos dados nele, no momento que o Pod fosse destru√≠do os dados iriam junto e sem backup !

Irei mostrar como resolver esse problema no pr√≥ximo post.

Pr√≥ximo Post: [clique aqui](https://medium.com/@lucassabreu/um-ambiente-simples-usando-kubernetes-e-openshift-next-gen-parte-3-a36e01e920cb)

Gostou do post e achou √∫til? D√™ um **like **‚ù§ abaixo para ajudar na divulga√ß√£o e para que mais pessoas tenham acesso **üòÑ**, e volte amanh√£ para acompanhar essa s√©rie sobre Kubernetes !
